{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e410036c-1692-4928-8fc0-b0ff6cca24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ce704-1130-4942-91b5-41669232f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()            # loading Stemming method for reducing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b13efec-38b9-455b-966f-fffccec38eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batting | bat\n",
      "fielding | field\n",
      "reliability | reliabl\n",
      "consumed | consum\n",
      "customer | custom\n",
      "walked | walk\n",
      "belt | belt\n"
     ]
    }
   ],
   "source": [
    "list_ele = ['batting', 'fielding', 'reliability', 'consumed', 'customer', 'walked', 'belt']\n",
    "for i in list_ele:\n",
    "    print(i, \"|\", stemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87eee55a-e35e-48a3-95fb-5804f30d1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "word = nlp(\" \".join(list_ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a147c3a1-fcb2-4f5c-912e-a8a3b68c81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batting | batting\n",
      "fielding | fielding\n",
      "reliability | reliability\n",
      "consumed | consume\n",
      "customer | customer\n",
      "walked | walk\n",
      "belt | belt\n"
     ]
    }
   ],
   "source": [
    "for i in word:\n",
    "    print(i.text, \"|\", i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b48c712-4ab6-4832-9ad6-5dcd06521042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62885ec5-aeed-44c2-820c-383ac2183923",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hi bro this is your friend, yes! bruhh i know you are my bruh!\"\n",
    "word = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e92e4a1-4541-4f99-aae8-3fa8833d0eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi | hi\n",
      "bro | bro\n",
      "this | this\n",
      "is | be\n",
      "your | your\n",
      "friend | friend\n",
      ", | ,\n",
      "yes | yes\n",
      "! | !\n",
      "bruhh | bruhh\n",
      "i | I\n",
      "know | know\n",
      "you | you\n",
      "are | be\n",
      "my | my\n",
      "bruh | bruh\n",
      "! | !\n"
     ]
    }
   ],
   "source": [
    "for i in word:\n",
    "    print(i, \"|\", i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343e8f39-365a-43ff-8418-fb836ede6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = nlp.get_pipe(\"attribute_ruler\")\n",
    "\n",
    "custom.add([[{'TEXT':'bro'}], [{'TEXT':'bruh'}], [{'TEXT':'bruhh'}]], {\"LEMMA\":\"brother\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "683f43d0-f8a4-461f-b26a-e1a7b8926398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi | hi\n",
      "bro | brother\n",
      "this | this\n",
      "is | be\n",
      "your | your\n",
      "friend | friend\n",
      ", | ,\n",
      "yes | yes\n",
      "! | !\n",
      "bruhh | brother\n",
      "i | I\n",
      "know | know\n",
      "you | you\n",
      "are | be\n",
      "my | my\n",
      "bruh | brother\n",
      "! | !\n"
     ]
    }
   ],
   "source": [
    "text = \"hi bro this is your friend, yes! bruhh i know you are my bruh!\"\n",
    "word = nlp(text)\n",
    "for i in word:\n",
    "    print(i, \"|\", i.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd47b9-568d-47be-ab51-83676ed181ea",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffe837d-ae90-45e6-8808-3ab8e16dd22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "for i in lst_words:\n",
    "    print(i, \"|\", stemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9b9f30-2e95-4e8e-b575-73fe7d0c5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | painting\n",
      "walking | walking\n",
      "dressing | dress\n",
      "likely | likely\n",
      "children | child\n",
      "who | who\n",
      "good | good\n",
      "ate | eat\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "for i in doc:\n",
    "    print(i, \"|\", i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93dee251-cdf4-4fef-b2e4-42a6f7ad3672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "who | who\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "doc = word_tokenize(\"running painting walking dressing likely children who good ate fishing\")\n",
    "for i in doc:\n",
    "    print(i, \"|\", stemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74e8263d-5180-4e63-aed4-b024775e1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b531579-97fe-45d8-b393-a4e415364c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = nlp(text)\n",
    "word2 = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4ad5e77-e42f-4a8e-bb8c-ac98f9a145e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Latha: 'Latha', is: 'be', very: 'very', multi: 'multi', talented: 'talented', girl: 'girl', .: '.', She: 'she', is: 'be', good: 'good', at: 'at', many: 'many', skills: 'skill', like: 'like', dancing: 'dancing', ,: ',', running: 'running', ,: ',', singing: 'singing', ,: ',', playing: 'play', .: '.', She: 'she', also: 'also', likes: 'like', eating: 'eat', Pav: 'Pav', Bhagi: 'Bhagi', .: '.', she: 'she', has: 'have', a: 'a', \n",
      ": '\\n', habit: 'habit', of: 'of', fishing: 'fishing', and: 'and', swimming: 'swim', too: 'too', .: '.', Besides: 'besides', all: 'all', this: 'this', ,: ',', she: 'she', is: 'be', a: 'a', wonderful: 'wonderful', at: 'at', cooking: 'cook', too: 'too', .: '.', \n",
      ": '\\n'}\n",
      "{'Latha': 'latha', 'is': 'is', 'very': 'veri', 'multi': 'multi', 'talented': 'talent', 'girl.She': 'girl.sh', 'good': 'good', 'at': 'at', 'many': 'mani', 'skills': 'skill', 'like': 'like', 'dancing': 'danc', ',': ',', 'running': 'run', 'singing': 'sing', 'playing.She': 'playing.sh', 'also': 'also', 'likes': 'like', 'eating': 'eat', 'Pav': 'pav', 'Bhagi': 'bhagi', '.': '.', 'she': 'she', 'has': 'ha', 'a': 'a', 'habit': 'habit', 'of': 'of', 'fishing': 'fish', 'and': 'and', 'swimming': 'swim', 'too.Besides': 'too.besid', 'all': 'all', 'this': 'thi', 'wonderful': 'wonder', 'cooking': 'cook', 'too': 'too'}\n"
     ]
    }
   ],
   "source": [
    "word1_1 = {i:i.lemma_ for i in word1}\n",
    "word2_2 = {i:stemmer.stem(i) for i in word2}\n",
    "print(word1_1)\n",
    "print(word2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e38d85-7efe-42b1-a860-fdd590052893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
